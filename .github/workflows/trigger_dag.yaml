name: Bank Marketing MLOps CI/CD

on:
  push:
    branches: hashwanth_model_cicd
  schedule:
    - cron: '0 0 * * *'  # Runs every day at midnight
  workflow_dispatch:

env:
  REGION: us-east4
  REPOSITORY_NAME: Bank_Marketing_Prediction_MLops
  GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  GCS_BUCKET_NAME: ${{ secrets.GCS_BUCKET_NAME }}
  PYTHON_VERSION: '3.10'

jobs:
  build_and_deploy_model:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Ensure PYTHONPATH includes dags/src for proper imports
      - name: Set PYTHONPATH for scripts
        run: |
          export PYTHONPATH=$PYTHONPATH:$GITHUB_WORKSPACE/dags/src

      # Run your model development script directly instead of triggering a DAG
      - name: Run model development script
        run: |
          python dags/src/Model_Pipeline/model_development_and_evaluation_with_mlflow.py

      # Run your model comparison script after training the models
      - name: Run model comparison script
        run: |
          python dags/src/Model_Pipeline/compare_best_models.py

      # Check for the trained model file (e.g., best_model.pkl)
      - name: Check for model file
        run: |
          echo "Current directory $(pwd)"
          echo "Contents of current directory:"
          ls -R
          echo "Searching for best_model.pkl:"
          find . -name best_model.pkl

      # Authenticate with Google Cloud Platform (GCP)
      - name: Authenticate with GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      # Upload the trained model to Google Cloud Storage (GCS)
      - name: Save and Upload Model to GCS
        run: |
          MODEL_FILE=$(find . -name best_model.pkl)
          if [ -z "$MODEL_FILE" ]; then;
            echo "Error best_model.pkl not found";
            exit 1;
          fi;
          echo "Uploading $MODEL_FILE to GCS";
          gsutil cp $MODEL_FILE gs://${{ env.GCS_BUCKET_NAME }}/models/best_model_${{ github.sha }}.pkl;

      # Deploy the trained model to AI Platform (optional)
      - name: Deploy Model to AI Platform (Optional)
        run: |
          gcloud ai models upload \
            --region=${{ env.REGION }} \
            --display-name=bank-marketing-model-${{ github.sha }} \
            --artifact-uri=gs://${{ env.GCS_BUCKET_NAME }}/models/best_model_${{ github.sha }}.pkl
