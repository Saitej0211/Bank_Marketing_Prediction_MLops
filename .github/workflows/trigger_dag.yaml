name: Bank Marketing MLOps CI/CD

on:
  push:
    branches: [ Sheela-ci_cd ]
  schedule:
    - cron: '0 0 * * *'  # Runs every day at midnight
  workflow_dispatch:

env:
  REGION: us-east4
  REPOSITORY_NAME: bank_marketing_prediction_mlops  
  GCP_PROJECT_ID: iconic-vine-438222-u6
  GCS_BUCKET_NAME: mlopsprojectdatabucketgrp6

jobs:
  build_test_and_deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Authenticate with GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Set GCP project ID
        run: gcloud config set project "${{ secrets.GCP_PROJECT_ID }}"

### Docker Build and Push Steps
      - name: Build and Push Docker Image
        env:
          IMAGE_NAME: ${{ env.REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ env.REPOSITORY_NAME }}/model-image
        run: |
          docker build -t ${IMAGE_NAME}:${{ github.sha }} .
          docker push ${IMAGE_NAME}:${{ github.sha }}
          docker tag ${IMAGE_NAME}:${{ github.sha }} ${IMAGE_NAME}:latest
          docker push ${IMAGE_NAME}:latest

### Continue with Airflow Setup and Model Deployment
      - name: Create directories for Airflow
        run: |
          mkdir -p ./dags ./logs ./plugins

      - name: Initialize Airflow Database
        run: |
          docker compose up airflow-init

      - name: Start Airflow services
        run: |
          docker compose up -d

      - name: Wait for Airflow to initialize
        run: |
          sleep 180  # Wait for 3 minutes

      - name: Check Airflow services status
        run: |
          docker compose ps

      - name: Trigger DAG and wait for completion
        run: |
          if docker compose ps | grep -q "airflow-webserver.*Up"; then
            echo "Triggering DAG..."
            docker compose exec airflow-webserver airflow dags trigger ModelDevelopmentPipeline
            
            echo "Waiting for DAG to complete..."
            while true; do
              STATUS=$(docker compose exec airflow-webserver airflow dags state ModelDevelopmentPipeline $(date +%Y-%m-%d))
              echo "Current DAG status: $STATUS"
              if [ "$STATUS" = "success" ]; then
                echo "DAG completed successfully"
                break
              elif [ "$STATUS" = "failed" ]; then
                echo "DAG failed"
                exit 1
              fi
              echo "DAG still running, waiting..."
              sleep 60
            done
          else
            echo "Airflow webserver is not running. Current status:"
            docker compose ps
            exit 1
          fi

### Model Upload and Deployment
      - name: Check for model file
        run: |
          echo "Current directory: $(pwd)"
          echo "Contents of current directory:"
          ls -R
          echo "Searching for best_model.pkl:"
          find . -name best_model.pkl

      - name: Save and Upload Model to GCS
        run: |
          MODEL_FILE=$(find . -name best_model.pkl)
          if [ -z "$MODEL_FILE" ]; then
            echo "Error: best_model.pkl not found"
            exit 1
          fi
          echo "Uploading $MODEL_FILE to GCS"
          gsutil cp $MODEL_FILE gs://${{ env.GCS_BUCKET_NAME }}/models/best_model_${{ github.sha }}.pkl

      - name: Deploy Model to AI Platform
        run: |
          gcloud ai models upload \
            --region=${{ env.REGION }} \
            --display-name=bank-marketing-model-${{ github.sha }} \
            --artifact-uri=gs://${{ env.GCS_BUCKET_NAME }}/models/best_model_${{ github.sha }}.pkl

### Final Cleanup and Notifications
      - name: Clean up
        if: always()
        run: docker compose down --volumes --rmi all

      - name: Deployment success message
        if: success()
        run: echo "CI/CD pipeline completed successfully. Model uploaded and services started."

      - name: Deployment failed notification
        if: failure()
        run: echo "CI/CD pipeline failed. Check the logs for details."
